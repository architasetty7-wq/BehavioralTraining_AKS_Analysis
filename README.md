## Project Overview
This project presents a data-driven evaluation of HANDS in Autism® offsite professional trainings conducted across Indiana and neighboring regions. The goal was to systematically assess participant satisfaction and changes in autism-related knowledge using structured REDCap evaluation data.

## Problem Statement
HANDS in Autism® conducts recurring professional trainings, but long-term evaluation required a scalable, repeatable analytics framework to:
- Measure participant satisfaction consistently
- Quantify autism knowledge gains (pre/post)
- Support data-informed instructional improvements

## Data Sources
- REDCap Daily Training Evaluation Forms  
- REDCap Autism Knowledge Survey (AKS)  
- Multi-day, multi-cohort training datasets (Springfield School District and others)

## Methods & Tools
- Data cleaning, transformation, and validation (Python, Pandas)
- Pre/post knowledge scoring and satisfaction analysis
- Reproducible analytics workflow
- Visualization and reporting (Matplotlib, Seaborn, Power BI)

**Tools:** Python, Pandas, NumPy, Matplotlib, Seaborn, REDCap, Excel

## Key Outcomes
- Identified consistently high satisfaction across training components
- Demonstrated measurable autism knowledge gains post-training
- Built a reusable evaluation framework supporting longitudinal analysis
- Enabled systematic outcome monitoring over time

## Impact
This work strengthened HANDS in Autism®’s evaluation capacity, supported continuous improvement of training programs, and demonstrated how structured analytics can bridge education, behavioral health, and informatics.
